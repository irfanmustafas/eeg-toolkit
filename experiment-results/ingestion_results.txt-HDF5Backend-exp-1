Using mrn: 005-1gb backend: HDF5Backend with desired_size: 1000000000 and READ_CHUNK_SIZE: 16000000
Converting mrn: 005-1gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 15625000, "nsamples": 15625000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-1gb,HDF5Backend,1000000000,16000000,239.844
Using mrn: 005-1gb backend: HDF5Backend with desired_size: 1000000000 and READ_CHUNK_SIZE: 32000000
Converting mrn: 005-1gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 15625000, "nsamples": 15625000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-1gb,HDF5Backend,1000000000,32000000,416.702
Using mrn: 005-1gb backend: HDF5Backend with desired_size: 1000000000 and READ_CHUNK_SIZE: 64000000
Converting mrn: 005-1gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 15625000, "nsamples": 15625000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-1gb,HDF5Backend,1000000000,64000000,732.04
Using mrn: 005-1gb backend: HDF5Backend with desired_size: 1000000000 and READ_CHUNK_SIZE: 128000000
Converting mrn: 005-1gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 15625000, "nsamples": 15625000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-1gb,HDF5Backend,1000000000,128000000,608.437
Using mrn: 005-2gb backend: HDF5Backend with desired_size: 2000000000 and READ_CHUNK_SIZE: 16000000
Converting mrn: 005-2gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 31250000, "nsamples": 31250000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-2gb,HDF5Backend,2000000000,16000000,341.352
Using mrn: 005-2gb backend: HDF5Backend with desired_size: 2000000000 and READ_CHUNK_SIZE: 32000000
Converting mrn: 005-2gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 31250000, "nsamples": 31250000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-2gb,HDF5Backend,2000000000,32000000,321.607
Using mrn: 005-2gb backend: HDF5Backend with desired_size: 2000000000 and READ_CHUNK_SIZE: 64000000
Converting mrn: 005-2gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 31250000, "nsamples": 31250000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-2gb,HDF5Backend,2000000000,64000000,600.633
Using mrn: 005-2gb backend: HDF5Backend with desired_size: 2000000000 and READ_CHUNK_SIZE: 128000000
Converting mrn: 005-2gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 31250000, "nsamples": 31250000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-2gb,HDF5Backend,2000000000,128000000,620.104
Using mrn: 005-4gb backend: HDF5Backend with desired_size: 4000000000 and READ_CHUNK_SIZE: 16000000
Converting mrn: 005-4gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 62500000, "nsamples": 62500000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-4gb,HDF5Backend,4000000000,16000000,703.446
Using mrn: 005-4gb backend: HDF5Backend with desired_size: 4000000000 and READ_CHUNK_SIZE: 32000000
Converting mrn: 005-4gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 62500000, "nsamples": 62500000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-4gb,HDF5Backend,4000000000,32000000,792.509
Using mrn: 005-4gb backend: HDF5Backend with desired_size: 4000000000 and READ_CHUNK_SIZE: 64000000
Converting mrn: 005-4gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 62500000, "nsamples": 62500000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-4gb,HDF5Backend,4000000000,64000000,869.93
Using mrn: 005-4gb backend: HDF5Backend with desired_size: 4000000000 and READ_CHUNK_SIZE: 128000000
Converting mrn: 005-4gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 62500000, "nsamples": 62500000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-4gb,HDF5Backend,4000000000,128000000,872.17
Using mrn: 005-8gb backend: HDF5Backend with desired_size: 8000000000 and READ_CHUNK_SIZE: 16000000
Converting mrn: 005-8gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 125000000, "nsamples": 125000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-8gb,HDF5Backend,8000000000,16000000,1201.51
Using mrn: 005-8gb backend: HDF5Backend with desired_size: 8000000000 and READ_CHUNK_SIZE: 32000000
Converting mrn: 005-8gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 125000000, "nsamples": 125000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-8gb,HDF5Backend,8000000000,32000000,1141.02
Using mrn: 005-8gb backend: HDF5Backend with desired_size: 8000000000 and READ_CHUNK_SIZE: 64000000
Converting mrn: 005-8gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 125000000, "nsamples": 125000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-8gb,HDF5Backend,8000000000,64000000,1130.8
Using mrn: 005-8gb backend: HDF5Backend with desired_size: 8000000000 and READ_CHUNK_SIZE: 128000000
Converting mrn: 005-8gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 125000000, "nsamples": 125000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-8gb,HDF5Backend,8000000000,128000000,1337.47
Using mrn: 005-16gb backend: HDF5Backend with desired_size: 16000000000 and READ_CHUNK_SIZE: 16000000
Converting mrn: 005-16gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 250000000, "nsamples": 250000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-16gb,HDF5Backend,16000000000,16000000,1449.39
Using mrn: 005-16gb backend: HDF5Backend with desired_size: 16000000000 and READ_CHUNK_SIZE: 32000000
Converting mrn: 005-16gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 250000000, "nsamples": 250000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-16gb,HDF5Backend,16000000000,32000000,1663
Using mrn: 005-16gb backend: HDF5Backend with desired_size: 16000000000 and READ_CHUNK_SIZE: 64000000
Converting mrn: 005-16gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 250000000, "nsamples": 250000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-16gb,HDF5Backend,16000000000,64000000,1703.77
Using mrn: 005-16gb backend: HDF5Backend with desired_size: 16000000000 and READ_CHUNK_SIZE: 128000000
Converting mrn: 005-16gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 250000000, "nsamples": 250000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-16gb,HDF5Backend,16000000000,128000000,1693.17
Using mrn: 005-32gb backend: HDF5Backend with desired_size: 32000000000 and READ_CHUNK_SIZE: 16000000
Converting mrn: 005-32gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 500000000, "nsamples": 500000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-32gb,HDF5Backend,32000000000,16000000,2768.57
Using mrn: 005-32gb backend: HDF5Backend with desired_size: 32000000000 and READ_CHUNK_SIZE: 32000000
Converting mrn: 005-32gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 500000000, "nsamples": 500000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-32gb,HDF5Backend,32000000000,32000000,2651.18
Using mrn: 005-32gb backend: HDF5Backend with desired_size: 32000000000 and READ_CHUNK_SIZE: 64000000
Converting mrn: 005-32gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 500000000, "nsamples": 500000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-32gb,HDF5Backend,32000000000,64000000,2792.18
Using mrn: 005-32gb backend: HDF5Backend with desired_size: 32000000000 and READ_CHUNK_SIZE: 128000000
Converting mrn: 005-32gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 500000000, "nsamples": 500000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-32gb,HDF5Backend,32000000000,128000000,2643.43
Using mrn: 005-64gb backend: HDF5Backend with desired_size: 64000000000 and READ_CHUNK_SIZE: 16000000
Converting mrn: 005-64gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 1000000000, "nsamples": 1000000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-64gb,HDF5Backend,64000000000,16000000,4873.07
Using mrn: 005-64gb backend: HDF5Backend with desired_size: 64000000000 and READ_CHUNK_SIZE: 32000000
Converting mrn: 005-64gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 1000000000, "nsamples": 1000000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-64gb,HDF5Backend,64000000000,32000000,6287.76
Using mrn: 005-64gb backend: HDF5Backend with desired_size: 64000000000 and READ_CHUNK_SIZE: 64000000
Converting mrn: 005-64gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 1000000000, "nsamples": 1000000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-64gb,HDF5Backend,64000000000,64000000,4882.71
Using mrn: 005-64gb backend: HDF5Backend with desired_size: 64000000000 and READ_CHUNK_SIZE: 128000000
Converting mrn: 005-64gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 1000000000, "nsamples": 1000000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-64gb,HDF5Backend,64000000000,128000000,8977.39
Using mrn: 005-128gb backend: HDF5Backend with desired_size: 128000000000 and READ_CHUNK_SIZE: 16000000
Converting mrn: 005-128gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 2000000000, "nsamples": 2000000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-128gb,HDF5Backend,128000000000,16000000,8190.16
Using mrn: 005-128gb backend: HDF5Backend with desired_size: 128000000000 and READ_CHUNK_SIZE: 32000000
Converting mrn: 005-128gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 2000000000, "nsamples": 2000000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-128gb,HDF5Backend,128000000000,32000000,5635.25
Using mrn: 005-128gb backend: HDF5Backend with desired_size: 128000000000 and READ_CHUNK_SIZE: 64000000
Converting mrn: 005-128gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 2000000000, "nsamples": 2000000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-128gb,HDF5Backend,128000000000,64000000,4283.69
Using mrn: 005-128gb backend: HDF5Backend with desired_size: 128000000000 and READ_CHUNK_SIZE: 128000000
Converting mrn: 005-128gb with 55377408 samples and fs=256
Array metadata: {"fs": 256, "ncols": 16, "nrows": 2000000000, "nsamples": 2000000000}
Wrote ch: 0
Wrote ch: 2
Wrote ch: 8
Wrote ch: 10
Wrote ch: 12
Wrote ch: 16
Wrote ch: 18
Wrote ch: 20
Write complete
experiment_data::005-128gb,HDF5Backend,128000000000,128000000,4129.71
